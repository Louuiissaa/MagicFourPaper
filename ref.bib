
@misc{QuickStartGuide,
  title = {Quick Start Guide [{{Zotero Documentation}}]},
  howpublished = {https://www.zotero.org/support/quick\_start\_guide},
  file = {C:\\Users\\TaiLe\\Zotero\\storage\\MCIHQG3Z\\quick_start_guide.html}
}

@misc{maryamMachineLearning,
  title = {Machine {{Learning}}},
  howpublished = {http://www.contrib.andrew.cmu.edu/\textasciitilde{}mndarwis/ML.html},
  author = {Maryam, AlDarwish},
  file = {C:\\Users\\TaiLe\\Zotero\\storage\\4JHGDI8V\\ML.html}
}

@misc{MachineLearning,
  title = {Machine {{Learning}}},
  howpublished = {http://www.contrib.andrew.cmu.edu/\textasciitilde{}mndarwis/ML.html}
}

@misc{MachineLearninga,
  title = {Machine {{Learning}}},
  howpublished = {http://www.contrib.andrew.cmu.edu/\textasciitilde{}mndarwis/ML.html}
}

@misc{MachineLearningb,
  title = {Machine {{Learning}}},
  howpublished = {http://www.contrib.andrew.cmu.edu/\textasciitilde{}mndarwis/ML.html}
}

@misc{nathanHistoryMachineLearning,
  title = {History of {{Machine Learning}}},
  howpublished = {https://sge.wonderville.ca/machinelearning/history/history.html},
  journal = {Dig in to Machine Learning},
  author = {Nathan, Amstrong},
  file = {C:\\Users\\TaiLe\\Zotero\\storage\\M9TV7U6D\\history.html}
}

@article{samuelStudiesMachineLearning1959,
  title = {Some {{Studies}} in {{Machine Learning Using}} the {{Game}} of {{Checkers}}},
  volume = {3},
  issn = {0018-8646},
  doi = {10.1147/rd.33.0210},
  abstract = {Two machine-learning procedures have been investigated in some detail using the game of checkers. Enough work has been done to verify the fact that a computer can be programmed so that it will learn to play a better game of checkers than can be played by the person who wrote the program. Furthermore, it can learn to do this in a remarkably short period of time (8 or 10 hours of machine-playing time) when given only the rules of the game, a sense of direction, and a redundant and incomplete list of parameters which are thought to have something to do with the game, but whose correct signs and relative weights are unknown and unspecified. The principles of machine learning verified by these experiments are, of course, applicable to many other situations.},
  number = {3},
  journal = {IBM Journal of Research and Development},
  author = {Samuel, A. L.},
  month = jul,
  year = {1959},
  pages = {210-229},
  file = {C:\\Users\\TaiLe\\Zotero\\storage\\NSW97KR5\\Samuel - 1959 - Some Studies in Machine Learning Using the Game of.pdf;C:\\Users\\TaiLe\\Zotero\\storage\\IM5CHT7S\\5392560.html}
}

@misc{sasMachineLearningWhat,
  title = {Machine {{Learning}}: {{What}} It Is and Why It Matters},
  shorttitle = {Machine {{Learning}}},
  abstract = {Find out what machine learning is, what kinds of algorithms and processes are used, and some of the many ways that machine learning is being used today.},
  language = {en},
  howpublished = {https://www.sas.com/en\_us/insights/analytics/machine-learning.html},
  author = {SAS},
  file = {C:\\Users\\TaiLe\\Zotero\\storage\\4G72QJZS\\machine-learning.html}
}

@article{deloitteglobalMachineLearningThings2017,
  title = {Machine {{Learning}}: {{Things Are Getting Intense}}},
  shorttitle = {Machine {{Learning}}},
  abstract = {Progress in five essential areas will likely make it faster and easier to develop machine learning solutions this year while also removing some of the barriers that have restricted adoption in the past. Among the results could be greater investment and more intensive use within enterprises.},
  language = {en-US},
  author = {Deloitte Global},
  year = {2017},
  file = {C:\\Users\\TaiLe\\Zotero\\storage\\GHZAQ2PX\\machine-learning-things-are-getting-intense-2.html}
}

@article{caveWhatWillWe2017,
  title = {What {{Will We Do When The World}}'s {{Data Hits}} 163 {{Zettabytes In}} 2025?},
  abstract = {The world's annual creation of data is predicted to grow ten-fold to 163 Zettabytes by 2025. What are we going to do with all this information? And how much of it will we want to store?},
  language = {en},
  journal = {Forbes},
  author = {Cave, Andrew},
  month = apr,
  year = {2017},
  file = {C:\\Users\\TaiLe\\Zotero\\storage\\M8W2XJGV\\what-will-we-do-when-the-worlds-data-hits-163-zettabytes-in-2025.html}
}

@book{marcelArtificialNeuralNetworks,
  title = {Artificial {{Neural Networks}} as {{Models}} of {{Neural Information Processing}} | {{Frontiers Research Topic}}},
  language = {en},
  author = {Marcel, van Gerven},
  file = {C:\\Users\\TaiLe\\Zotero\\storage\\EBM7KTWZ\\artificial-neural-networks-as-models-of-neural-information-processing.html}
}

@article{marcelEditorialArtificialNeural2017,
  title = {Editorial: {{Artificial Neural Networks}} as {{Models}} of {{Neural Information Processing}}},
  volume = {11},
  issn = {1662-5188},
  shorttitle = {Editorial},
  doi = {10.3389/fncom.2017.00114},
  abstract = {Editorial: Artificial Neural Networks as Models of Neural Information Processing},
  language = {English},
  journal = {Frontiers in Computational Neuroscience},
  author = {Marcel, van Gerven and Sander, Bohte},
  year = {2017},
  keywords = {artificial intelligence,computational neuroscience,neural networks,rate coding,spiking neural networks},
  file = {C:\\Users\\TaiLe\\Zotero\\storage\\SRSENF6R\\van Gerven and Bohte - 2017 - Editorial Artificial Neural Networks as Models of.pdf}
}

@article{christosNeuralNetworks1996,
  title = {Neural {{Networks}}},
  volume = {4},
  author = {Christos, Stergiou and Dimitrios, Siganos},
  year = {1996},
  file = {C:\\Users\\TaiLe\\Zotero\\storage\\DGK55T7G\\report.html}
}

@incollection{goodfellowDeepLearning2016,
  title = {Deep {{Learning}}},
  isbn = {978-0-262-03561-3},
  publisher = {{MIT Press}},
  author = {Goodfellow, Ian and Bengio, Yoshua and Courville, Aaaron},
  year = {2016},
  pages = {196}
}

@book{mitchellIntroductionGeneticAlgorithms1996,
  title = {An {{Introduction}} to {{Genetic Algorithms}}},
  isbn = {978-0-585-03094-4},
  publisher = {{Cambridge}},
  author = {Mitchell, Melanie},
  year = {1996}
}

@article{javadOptimisingMultiitemEconomic2016,
  title = {Optimising Multi-Item Economic Production Quantity Model with Trapezoidal Fuzzy Demand and Backordering: Two Tuned Meta-Heuristics},
  author = {Javad, Sadeghi},
  year = {2016},
  file = {C:\\Users\\TaiLe\\Zotero\\storage\\3CPU9QUI\\offer.html}
}

@misc{connerGoogleAssistantCheat2018,
  title = {Google {{Assistant}}: {{A}} Cheat Sheet},
  shorttitle = {Google {{Assistant}}},
  abstract = {This comprehensive guide covers the history behind Google's AI-powered Google Assistant, its features, and what it means for the future of Google's business.},
  language = {en},
  howpublished = {https://www.techrepublic.com/article/google-assistant-the-smart-persons-guide/},
  journal = {TechRepublic},
  author = {Conner, Forrest},
  month = may,
  year = {2018},
  file = {C:\\Users\\TaiLe\\Zotero\\storage\\4IYWL79Q\\google-assistant-the-smart-persons-guide.html}
}

@misc{singhHowGoogleAssistant2016,
  title = {How Is {{Google Assistant}} Using {{Artificial Intelligence AI}}},
  abstract = {Google Pixel smartphone and Google Home leverage Google Assistant Artificial Intelligence AI fully voice-enabled interface},
  language = {en-US},
  journal = {Geospatial World},
  author = {Singh, Ishveena},
  month = oct,
  year = {2016},
  file = {C:\\Users\\TaiLe\\Zotero\\storage\\ZDIYJN3I\\how-is-google-assistant-using-artificial-intelligence-ai.html}
}

@misc{mackenzieHowRetailersCan2013,
  title = {How Retailers Can Keep up with Consumers | {{McKinsey}}},
  abstract = {The retail industry is more dynamic than ever. US retailers must evolve to succeed in the next decade.},
  language = {en},
  howpublished = {https://www.mckinsey.com/industries/retail/our-insights/how-retailers-can-keep-up-with-consumers},
  author = {MacKenzie, Ian and Meyer, Chris and Noble, Steve},
  month = oct,
  year = {2013},
  file = {C:\\Users\\TaiLe\\Zotero\\storage\\UPLRJZE4\\how-retailers-can-keep-up-with-consumers.html}
}

@misc{DISTemplateGoogle,
  title = {{{DIS}} Template - {{Google Search}}},
  howpublished = {https://www.google.no/search?q=DIS+template\&rlz=1C1GCEU\_enNO821NO821\&oq=DIS+template\&aqs=chrome..69i57.4615j0j4\&sourceid=chrome\&ie=UTF-8},
  file = {C:\\Users\\TaiLe\\Zotero\\storage\\6XT6CD9U\\search.html}
}

@article{perezEffectivenessDataAugmentation2017,
  archivePrefix = {arXiv},
  eprinttype = {arxiv},
  eprint = {1712.04621},
  primaryClass = {cs},
  title = {The {{Effectiveness}} of {{Data Augmentation}} in {{Image Classification}} Using {{Deep Learning}}},
  abstract = {In this paper, we explore and compare multiple solutions to the problem of data augmentation in image classification. Previous work has demonstrated the effectiveness of data augmentation through simple techniques, such as cropping, rotating, and flipping input images. We artificially constrain our access to data to a small subset of the ImageNet dataset, and compare each data augmentation technique in turn. One of the more successful data augmentations strategies is the traditional transformations mentioned above. We also experiment with GANs to generate images of different styles. Finally, we propose a method to allow a neural net to learn augmentations that best improve the classifier, which we call neural augmentation. We discuss the successes and shortcomings of this method on various datasets.},
  journal = {arXiv:1712.04621 [cs]},
  author = {Perez, Luis and Wang, Jason},
  month = dec,
  year = {2017},
  keywords = {Computer Science - Computer Vision and Pattern Recognition},
  file = {C:\\Users\\TaiLe\\Zotero\\storage\\8MNVLQG5\\Perez and Wang - 2017 - The Effectiveness of Data Augmentation in Image Cl.pdf;C:\\Users\\TaiLe\\Zotero\\storage\\PH63JZBL\\1712.html}
}

@misc{PDFIncreasingDeep,
  title = {({{PDF}}) {{Increasing Deep Learning Melanoma Classification}} by {{Classical And Expert Knowledge Based Image Transforms}}},
  abstract = {PDF | Skin cancer is a major public health problem, as is the most common type of cancer and represents more than half of cancer diagnoses worldwide. Early detection influences the outcome of the disease and motivates our work. We obtain the state of the art results for the ISBI...},
  language = {en},
  howpublished = {https://www.researchgate.net/publication/313910523\_Increasing\_Deep\_Learning\_Melanoma\_Classification\_by\_Classical\_And\_Expert\_Knowledge\_Based\_Image\_Transforms},
  journal = {ResearchGate},
  file = {C:\\Users\\TaiLe\\Zotero\\storage\\KIRQ9LVD\\313910523_Increasing_Deep_Learning_Melanoma_Classification_by_Classical_And_Expert_Knowledge_Ba.html}
}

@article{vasconcelosConvolutionalNeuralNetwork2017,
  archivePrefix = {arXiv},
  eprinttype = {arxiv},
  eprint = {1702.07025},
  primaryClass = {cs},
  title = {Convolutional {{Neural Network Committees}} for {{Melanoma Classification}} with {{Classical And Expert Knowledge Based Image Transforms Data Augmentation}}},
  abstract = {Skin cancer is a major public health problem, as is the most common type of cancer and represents more than half of cancer diagnoses worldwide. Early detection influences the outcome of the disease and motivates our work. We investigate the composition of CNN committees and data augmentation for the the ISBI 2017 Melanoma Classification Challenge (named Skin Lesion Analysis towards Melanoma Detection) facing the peculiarities of dealing with such a small, unbalanced, biological database. For that, we explore committees of Convolutional Neural Networks trained over the ISBI challenge training dataset artificially augmented by both classical image processing transforms and image warping guided by specialist knowledge about the lesion axis and improve the final classifier invariance to common melanoma variations.},
  journal = {arXiv:1702.07025 [cs]},
  author = {Vasconcelos, Cristina Nader and Vasconcelos, B\'arbara Nader},
  month = feb,
  year = {2017},
  keywords = {Computer Science - Computer Vision and Pattern Recognition},
  file = {C:\\Users\\TaiLe\\Zotero\\storage\\WI4F4RXU\\Vasconcelos and Vasconcelos - 2017 - Convolutional Neural Network Committees for Melano.pdf;C:\\Users\\TaiLe\\Zotero\\storage\\UN45GRPR\\1702.html}
}

@article{vasconcelosIncreasingDeepLearning2017,
  title = {Increasing {{Deep Learning Melanoma Classification}} by {{Classical And Expert Knowledge Based Image Transforms}}},
  volume = {abs/1702.07025},
  abstract = {Skin cancer is a major public health problem, as is the most common type of cancer and represents more than half of cancer diagnoses worldwide. Early detection influences the outcome of the disease and motivates our work. We obtain the state of the art results for the ISBI 2016 Melanoma Classification Challenge (named Skin Lesion Analysis towards Melanoma Detection) facing the peculiarities of dealing with such a small, unbalanced, biological database. For that, we explore committees of Convolutional Neural Networks trained over the ISBI challenge training dataset artificially augmented by both classical image processing transforms and image warping guided by specialist knowledge about the lesion axis and improve the final classifier invariance to common melanoma variations.},
  journal = {CoRR},
  author = {Vasconcelos, Cristina Nader and Vasconcelos, B\'arbara Nader},
  year = {2017},
  keywords = {Apache Axis,Biological database,Convolutional neural network,Deep learning,Image processing,Image warping,Unbalanced circuit},
  file = {C:\\Users\\TaiLe\\Zotero\\storage\\ZXUZR4R7\\Vasconcelos and Vasconcelos - 2017 - Increasing Deep Learning Melanoma Classification b.pdf}
}

@article{xuImprovedRelationClassification2016,
  title = {Improved {{Relation Classification}} by {{Deep Recurrent Neural Networks}} with {{Data Augmentation}}},
  language = {en},
  author = {Xu, Yan and Jia, Ran and Mou, Lili and Li, Ge and Chen, Yunchuan and Lu, Yangyang and Jin, Zhi},
  month = jan,
  year = {2016},
  file = {C:\\Users\\TaiLe\\Zotero\\storage\\YFIF2GIP\\Xu et al. - 2016 - Improved Relation Classification by Deep Recurrent.pdf;C:\\Users\\TaiLe\\Zotero\\storage\\VWS3CIXR\\1601.html}
}

@article{wongUnderstandingDataAugmentation2016,
  archivePrefix = {arXiv},
  eprinttype = {arxiv},
  eprint = {1609.08764},
  primaryClass = {cs},
  title = {Understanding Data Augmentation for Classification: When to Warp?},
  shorttitle = {Understanding Data Augmentation for Classification},
  abstract = {In this paper we investigate the benefit of augmenting data with synthetically created samples when training a machine learning classifier. Two approaches for creating additional training samples are data warping, which generates additional samples through transformations applied in the data-space, and synthetic over-sampling, which creates additional samples in feature-space. We experimentally evaluate the benefits of data augmentation for a convolutional backpropagation-trained neural network, a convolutional support vector machine and a convolutional extreme learning machine classifier, using the standard MNIST handwritten digit dataset. We found that while it is possible to perform generic augmentation in feature-space, if plausible transforms for the data are known then augmentation in data-space provides a greater benefit for improving performance and reducing overfitting.},
  journal = {arXiv:1609.08764 [cs]},
  author = {Wong, Sebastien C. and Gatt, Adam and Stamatescu, Victor and McDonnell, Mark D.},
  month = sep,
  year = {2016},
  keywords = {Computer Science - Computer Vision and Pattern Recognition,I.4.7,I.5.2},
  file = {C:\\Users\\TaiLe\\Zotero\\storage\\LJHM48XG\\Wong et al. - 2016 - Understanding data augmentation for classification.pdf;C:\\Users\\TaiLe\\Zotero\\storage\\PXSYR7D3\\1609.html}
}

@incollection{yaegerEffectiveTrainingNeural1997,
  title = {Effective {{Training}} of a {{Neural Network Character Classifier}} for {{Word Recognition}}},
  booktitle = {Advances in {{Neural Information Processing Systems}} 9},
  publisher = {{MIT Press}},
  author = {Yaeger, Larry S. and Lyon, Richard F. and Webb, Brandyn J.},
  editor = {Mozer, M. C. and Jordan, M. I. and Petsche, T.},
  year = {1997},
  pages = {807--816},
  file = {C:\\Users\\TaiLe\\Zotero\\storage\\32LELIFC\\Yaeger et al. - 1997 - Effective Training of a Neural Network Character C.pdf;C:\\Users\\TaiLe\\Zotero\\storage\\DHZ3PS4X\\1250-effective-training-of-a-neural-network-character-classifier-for-word-recognition.html}
}

@inproceedings{simardBestPracticesConvolutional2003,
  title = {Best Practices for Convolutional Neural Networks Applied to Visual Document Analysis},
  doi = {10.1109/ICDAR.2003.1227801},
  booktitle = {Seventh {{International Conference}} on {{Document Analysis}} and {{Recognition}}, 2003. {{Proceedings}}.},
  author = {Simard, P. Y. and Steinkraus, D. and Platt, J. C.},
  month = aug,
  year = {2003},
  keywords = {Best practices,Concrete,Convolution,Handwriting recognition,Industrial training,Information processing,Neural networks,Performance analysis,Support vector machines,Text analysis},
  pages = {958-963},
  file = {C:\\Users\\TaiLe\\Zotero\\storage\\9TM8YYUQ\\Simard et al. - 2003 - Best practices for convolutional neural networks a.pdf;C:\\Users\\TaiLe\\Zotero\\storage\\QWDVPWIN\\1227801.html}
}

@article{ciresanDeepBigSimple2010,
  title = {Deep, {{Big}}, {{Simple Neural Nets}} for {{Handwritten Digit Recognition}}},
  volume = {22},
  issn = {0899-7667},
  doi = {10.1162/NECO_a_00052},
  abstract = {Good old online backpropagation for plain multilayer perceptrons yields a very low 0.35\% error rate on the MNIST handwritten digits benchmark. All we need to achieve this best result so far are many hidden layers, many neurons per layer, numerous deformed training images to avoid overfitting, and graphics cards to greatly speed up learning.},
  number = {12},
  journal = {Neural Computation},
  author = {Cire{\c s}an, D. C. and Meier, U. and Gambardella, L. M. and Schmidhuber, J.},
  month = dec,
  year = {2010},
  pages = {3207-3220},
  file = {C:\\Users\\TaiLe\\Zotero\\storage\\SKUHT7UU\\Cire≈üan et al. - 2010 - Deep, Big, Simple Neural Nets for Handwritten Digi.pdf;C:\\Users\\TaiLe\\Zotero\\storage\\CSE6YTU7\\6797043.html}
}

@article{zhangLearningClassifiersSynthetic2015,
  archivePrefix = {arXiv},
  eprinttype = {arxiv},
  eprint = {1503.03163},
  primaryClass = {cs},
  title = {Learning {{Classifiers}} from {{Synthetic Data Using}} a {{Multichannel Autoencoder}}},
  abstract = {We propose a method for using synthetic data to help learning classifiers. Synthetic data, even is generated based on real data, normally results in a shift from the distribution of real data in feature space. To bridge the gap between the real and synthetic data, and jointly learn from synthetic and real data, this paper proposes a Multichannel Autoencoder(MCAE). We show that by suing MCAE, it is possible to learn a better feature representation for classification. To evaluate the proposed approach, we conduct experiments on two types of datasets. Experimental results on two datasets validate the efficiency of our MCAE model and our methodology of generating synthetic data.},
  journal = {arXiv:1503.03163 [cs]},
  author = {Zhang, Xi and Fu, Yanwei and Zang, Andi and Sigal, Leonid and Agam, Gady},
  month = mar,
  year = {2015},
  keywords = {Computer Science - Computer Vision and Pattern Recognition,Computer Science - Machine Learning},
  file = {C:\\Users\\TaiLe\\Zotero\\storage\\CDNKIYYL\\Zhang et al. - 2015 - Learning Classifiers from Synthetic Data Using a M.pdf;C:\\Users\\TaiLe\\Zotero\\storage\\C4UFYMR6\\1503.html}
}

@incollection{houdeChapter16What1997,
  address = {Amsterdam},
  title = {Chapter 16 - {{What}} Do {{Prototypes Prototype}}?},
  isbn = {978-0-444-81862-1},
  abstract = {Prototypes are widely recognized to be a core means of exploring and expressing designs for interactive computer artifacts. Choosing the right kind of more focused prototype to build is an art in itself, and communicating its limited purposes to its various audiences is a critical aspect of its use. Current terminology for describing prototypes centers on attributes of prototypes themselves that can be distracting. Tools can be used in many different ways, and detail is not a sure indicator of completion. This chapter proposes a change in the language used to talk about prototypes, to focus more on fundamental questions about the interactive system being designed. The goal of this chapter is to establish a model that describes any prototype in terms of the artifact being designed rather than the prototype's incidental attributes. By focusing on the purpose of the prototype\textemdash{}that is, what it prototypes\textemdash{}better decisions can be made about the kinds of prototypes to build. With a clear purpose for each prototype, prototypes can be better used to think and communicate about design. This chapter begins by describing current difficulties in communicating about prototypes: the complexity of interactive systems; issues of multi-disciplinary teamwork; and the audiences of prototypes. The chapter introduces the model and illustrates it with some initial examples of prototypes from real projects. The chapter concludes with a summary of the main implications of the model for prototyping practice.},
  booktitle = {Handbook of {{Human}}-{{Computer Interaction}} ({{Second Edition}})},
  publisher = {{North-Holland}},
  author = {Houde, Stephanie and Hill, Charles},
  editor = {Helander, Marting G. and Landauer, Thomas K. and Prabhu, Prasad V.},
  month = jan,
  year = {1997},
  pages = {367-381},
  file = {C:\\Users\\TaiLe\\Zotero\\storage\\A9F2LPKX\\Houde and Hill - 1997 - Chapter 16 - What do Prototypes Prototype.pdf;C:\\Users\\TaiLe\\Zotero\\storage\\NRTL2KKG\\B9780444818621500820.html},
  doi = {10.1016/B978-044481862-1.50082-0}
}


